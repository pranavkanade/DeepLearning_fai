{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]}},"cells":[{"metadata":{"id":"HHG5xW52D2Me","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# This file contains the code for RNN in order to fulfil fast.ai part1\n","\n","%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","from fastai.io import *\n","from fastai.conv_learner import *\n","\n","from fastai.column_data import *\n","\n","# --------------------# \n","# I'm going to download the collectd works of Nietzshe to use as our data for this \n","PATH='data/nietzsche/'\n","# --------------------#\n","get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n","text = open(f'{PATH}nietzsche.txt').read()\n","\n","# find the length of the dataset\n","print(\"corpus length : \", len(text))\n","\n","# looking at the data\n","print(text[:200])\n","\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars) + 1     # total number of characters used in the dataset\n","print('total chars : ', vocab_size)\n","\n","\n","# Sometimes its useful to have a zero value in the dataset, for padding\n","chars.insert(0, \"\\0\")\n","print(''.join(chars))       # '\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'\n","\n","\n","# I'll need mapping somewhere down the line\n","char_indices = {c : i for i, c in enumerate(chars)}\n","indices_char = {i : c for i, c in enumerate(chars)}\n","\n","# `idx` will contain whole data in form of indices\n","idx = [char_indices[c] for c in text]           # this converts the whole text file into a list of indices.\n","# take a look at some of the data\n","print(idx[:10])\n","\n","# check if the conversion is good or not\n","''.join(indices_char[i] for i in idx[:70])\n","\n","## Three char model \n","# Create inputs \n","# create a lit of every 4th charactern starting at 0th, 1st, 2nd then 3rd characters\n","cs = 3\n","# I'll only go till len(idx)-cs as I loop over this to find every 4th char, hence will omit last 3 chars\n","c1_dat = [idx[i] for i in range(0, len(idx)-cs, cs)]\n","c2_dat = [idx[i+1] for i in range(0, len(idx)-cs, cs)]\n","c3_dat = [idx[i+2] for i in range(0, len(idx)-cs, cs)]\n","c4_dat = [idx[i+3] for i in range(0, len(idx)-cs, cs)]\n","\n","# use `np.stack` to create an input\n","x1 = np.stack(c1_dat)\n","x2 = np.stack(c2_dat)\n","x3 = np.stack(c3_dat)\n","\n","# Above inputs will create an output as follows\n","y = np.stack(c4_dat)\n","\n","# hence i need to crea a net which does following : \n","# (x1, x2, x3 => RNN => x4)\n","\n","# take a look at some inputs and outputs\n","print(x1[:2], x2[:2], x3[:2], y[:2])\n","\n","# find out the number of i/o pairs we have as training data\n","print(x1.shape)\n","print(y.shape)\n","\n","# above two values should match, as num of inp = num of out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TobCTRCyEIJp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","# _____________________ Create and Train model ___________________ #\n","\n","# pick a size for out hidden state\n","n_hidden = 256\n","# size of embedding matrix\n","n_fac = 42\n","\n","class Char3Model(nn.Module):\n","    def __init__(self, vocab_size, n_fac):\n","        super().__init__()\n","        self.e = nn.Embedding(vocab_size, n_fac)\n","\n","        # input layer\n","        self.l_in = nn.Linear(n_fac, n_hidden)\n","\n","        # hidden layer\n","        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n","\n","        # output layer          # this out vector will be one hot encoded\n","        self.l_out = nn.Linear(n_hidden, vocab_size)\n","\n","\n","    def forward(self, c1, c2, c3):\n","        in1 = F.relu(self.l_in(self.e(c1)))\n","        in2 = F.relu(self.l_in(self.e(c2)))\n","        in3 = F.relu(self.l_in(self.e(c3)))\n","\n","        h = V(torch.zeros(in1.size()).cuda())\n","        h = F.tanh(self.l_hidden(h+in1))\n","        h = F.tanh(self.l_hidden(h+in2))\n","        h = F.tanh(self.l_hidden(h+in3))\n","\n","        return F.log_softmax(self.l_out(h))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LRk79k8NENsQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}